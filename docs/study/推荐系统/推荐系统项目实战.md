# 推荐系统项目实战

## 1. 基于Flink技术的商品实时推荐系统(初版)

> 之前趁着寒假有时间，学了一下大数据的基础知识，Hadoop、Hbase、Flink、Kafka等。做了一个简单的推荐系统。
### 1.0 演示视频

> [基于Flink的实时推荐系统-初版(ps录制的时候卡卡的)](https://www.bilibili.com/video/BV1k64y1U7VC/)

&nbsp;&nbsp;&nbsp;&nbsp;录制视频的时候，开的软件有点多，加上为了方便演示，把一些时间间隔参数调小了，所以CPU一直在运作，比较卡顿。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210405141609341.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FzaGlhbWQ=,size_16,color_FFFFFF,t_70)

### 1.1 关于推荐算法

&nbsp;&nbsp;&nbsp;&nbsp;推荐算法，用到的是SlopeOne。原本打算把TF-IDF也整合进去（另一个demo工程里已经实现），但是目前需要忙的其他事情较多，只好暂时作罢（等之后各事安定下来，会抽时间完善TF-IDF部分）。

&nbsp;&nbsp;&nbsp;&nbsp;关于SlopeOne算法，这里不多做介绍，这里推荐一本书，《写给程序员的数据挖掘实践指南》。我当时找各种学习材料，也看完了《推荐系统实践》这本书，最后还是觉得《写给程序员的数据挖掘实践指南》更适合小白入门推荐算法的学习。
### 1.2 使用的技术栈

&nbsp;&nbsp;&nbsp;&nbsp;这里主要是学习为主，所以技术选型，大多是出于模拟实际场景。（即其实我并没有那么大的数量级，但是假装自己就是处在那个数量级环境下）。

这里选用的技术主要如下：
+ SpringBoot （传统的后端搭建，主要负责用户信息、标签、商品信息的展示）
+ Flink（负责热门商品、热门标签统计、SlopeOne推荐计算）
+ Redis（存储热门商品ID集合、热门标签ID集合、SlopeOne推荐ID集合）
+ MySQL（传统的用户、标签、商品等关系型数据存储）
+ Nginx（反向代理，产生日志，Flink的数据来源）
+ Flume（日志收集，将Nginx日志收集到Kafka中）
+ Kafka（消息队列，同时也是Flink的数据源source）
+ HBase（存储统计数据、SlopeOne推荐结果，需要依赖Hadoop环境）
+ Hadoop环境
+ Vue（前端页面搭建，主要繁琐的点即组件的封装）
### 1.3 大致流程

1. 前端Vue发起请求，Nginx产生日志
2. Flume监听Nginx日志文件的变动，将新数据传输到Kafka
3. Flink监听Kafka变动，过滤筛选用户行为数据
4. Flink统计热门商品、热门标签；周期计算SlopeOne推荐列表

&nbsp;&nbsp;&nbsp;&nbsp;项目中的SpringBoot模块和两个Flink模块（热门统计、SlopeOne计算）解耦合，Vue前端只从SpringBoot后端获取到数据，而关于热门商品推荐、热门标签、SlopeOne推荐列表等数据，SpringBoot从Redis中读取，无需感知Flink的存在。
&nbsp;&nbsp;&nbsp;&nbsp;Flink模块会监听用户的行为数据，把被“交互”过的商品从用户的Redis推荐列表中剔除，避免重复推荐。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210405142415890.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FzaGlhbWQ=,size_16,color_FFFFFF,t_70)
### 1.4 商品数据来源

&nbsp;&nbsp;&nbsp;&nbsp;商品的数据，主要采集于京东商城。采取各种类别的商品，共1000条商品数据。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210405143019752.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FzaGlhbWQ=,size_16,color_FFFFFF,t_70)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210405143040364.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FzaGlhbWQ=,size_16,color_FFFFFF,t_70)

### 1.5 用户行为数据

&nbsp;&nbsp;&nbsp;&nbsp;这部分，我本地通过ApiFox编写自动HTTP请求的脚本，预先产生了一部分用户行为，Nginx也就对应的有日志记录了。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210405143237794.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FzaGlhbWQ=,size_16,color_FFFFFF,t_70)
### 1.6 SlopeOne推荐数据

&nbsp;&nbsp;&nbsp;&nbsp;因为预先通过脚本，进行了用户行为模拟，所以SlopeOne也已经计算出一定量的推荐数据来了。就HBase而言，有488W行的推荐数据。
（这里，SlopeOne模块生成的推荐列表，只推荐用户没有交互过的商品，交互过的不会重复推荐。）
![在这里插入图片描述](https://img-blog.csdnimg.cn/2021040514352975.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FzaGlhbWQ=,size_16,color_FFFFFF,t_70)

### 1.7 代码实现

&nbsp;&nbsp;&nbsp;&nbsp;后端项目大致代码结构层级如下：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210405142655372.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FzaGlhbWQ=,size_16,color_FFFFFF,t_70)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210405142744331.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FzaGlhbWQ=,size_16,color_FFFFFF,t_70)
&nbsp;&nbsp;&nbsp;&nbsp;前端Vue项目结构大致如下
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210405143714996.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FzaGlhbWQ=,size_16,color_FFFFFF,t_70)
### 1.8 结语

&nbsp;&nbsp;&nbsp;&nbsp;该项目是本人的毕业设计项目，等到毕业论文等相关事项结束后，会整理代码、数据库设计等相关材料，然后开源到我个人的[github](https://github.com/Ashiamd)上。

